{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8TbrTgEIxVW",
        "outputId": "37ed9174-bc2b-4970-f2f8-dd51bd826a63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CWPSqGe6JU_X"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "file_path = 'Shuffled_Dataset.xlsx'\n",
        "df = pd.read_excel(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ನಾನು ಒಳ್ಳೆಯದನ್ನು ಮೆಚ್ಚುತ್ತೇನೆ</td>\n",
              "      <td>Joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ಶಾಲಾ ಬಸ್ ನಿಲ್ದಾಣದಲ್ಲಿ ಮಕ್ಕಳು ಬಸ್‌ಗಾಗಿ ನಿರೀಕ್ಷಿ...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ನನ್ನ ಹಳೆಯ ಮಿತ್ರನು ನನ್ನ ಕೈ ಹಿಡಿದಾಗ ನನಗೆ ಅನುಭವವಾ...</td>\n",
              "      <td>Surprise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ನಾನು ಅದನ್ನು ಅನುಭವಿಸುತ್ತೇನೆ ಮತ್ತು ನಾನು ಅತೃಪ್ತಿ ...</td>\n",
              "      <td>Sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ಈ ಹೋಟೆಲ್‌ನ ಆಹಾರದಲ್ಲಿ ಕೀಟಗಳು ಕಂಡುಬಂದಿವೆ.</td>\n",
              "      <td>Disgust</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence   Emotion\n",
              "0                      ನಾನು ಒಳ್ಳೆಯದನ್ನು ಮೆಚ್ಚುತ್ತೇನೆ       Joy\n",
              "1  ಶಾಲಾ ಬಸ್ ನಿಲ್ದಾಣದಲ್ಲಿ ಮಕ್ಕಳು ಬಸ್‌ಗಾಗಿ ನಿರೀಕ್ಷಿ...   Neutral\n",
              "2  ನನ್ನ ಹಳೆಯ ಮಿತ್ರನು ನನ್ನ ಕೈ ಹಿಡಿದಾಗ ನನಗೆ ಅನುಭವವಾ...  Surprise\n",
              "3  ನಾನು ಅದನ್ನು ಅನುಭವಿಸುತ್ತೇನೆ ಮತ್ತು ನಾನು ಅತೃಪ್ತಿ ...       Sad\n",
              "4            ಈ ಹೋಟೆಲ್‌ನ ಆಹಾರದಲ್ಲಿ ಕೀಟಗಳು ಕಂಡುಬಂದಿವೆ.   Disgust"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UdIjPkVkJU71"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ಒಳ್ಳೆಯದನ್ನು ಮೆಚ್ಚುತ್ತೇನೆ</td>\n",
              "      <td>Joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ಶಾಲಾ ಬಸ್ ನಿಲ್ದಾಣದಲ್ಲಿ ಮಕ್ಕಳು ಬಸ್ಗಾಗಿ ನಿರೀಕ್ಷಿಸ...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ಹಳೆಯ ಮಿತ್ರನು ಕೈ ಹಿಡಿದಾಗ ಅನುಭವವಾಯಿತು</td>\n",
              "      <td>Surprise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ಅನುಭವಿಸುತ್ತೇನೆ ಅತೃಪ್ತಿ ಹೊಂದಿದ್ದೇನೆ</td>\n",
              "      <td>Sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ಹೋಟೆಲ್ನ ಆಹಾರದಲ್ಲಿ ಕೀಟಗಳು ಕಂಡುಬಂದಿವೆ</td>\n",
              "      <td>Disgust</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence   Emotion\n",
              "0                           ಒಳ್ಳೆಯದನ್ನು ಮೆಚ್ಚುತ್ತೇನೆ       Joy\n",
              "1  ಶಾಲಾ ಬಸ್ ನಿಲ್ದಾಣದಲ್ಲಿ ಮಕ್ಕಳು ಬಸ್ಗಾಗಿ ನಿರೀಕ್ಷಿಸ...   Neutral\n",
              "2                ಹಳೆಯ ಮಿತ್ರನು ಕೈ ಹಿಡಿದಾಗ ಅನುಭವವಾಯಿತು  Surprise\n",
              "3                 ಅನುಭವಿಸುತ್ತೇನೆ ಅತೃಪ್ತಿ ಹೊಂದಿದ್ದೇನೆ       Sad\n",
              "4                ಹೋಟೆಲ್ನ ಆಹಾರದಲ್ಲಿ ಕೀಟಗಳು ಕಂಡುಬಂದಿವೆ   Disgust"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Manually defined list of common Kannada stopwords\n",
        "stop_words = set([\n",
        "    'ನಾನು', 'ಅದು', 'ಅವರು', 'ಮತ್ತು', 'ಈ', 'ಇದು', 'ಎಂದು', 'ಆ', 'ಅದೇ', 'ಇದನ್ನು',\n",
        "    'ನಾವು', 'ಅದನ್ನು', 'ನಿನ್ನ', 'ನನಗೆ', 'ಅವನು', 'ಅವಳು', 'ನ', 'ನಿಮ್ಮ', 'ಅವಳ', 'ಅವನ',\n",
        "    'ನನ್ನ', 'ಮಾಡಲು', 'ಮಾಡಿದ', 'ಮತ್ತು', 'ಅದರ'\n",
        "])\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^\\w\\s\\u0C80-\\u0CFF]', '', text)  # Retain Kannada characters\n",
        "    text = re.sub(r'\\n', '', text)\n",
        "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
        "    text = text.lower()\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "\n",
        "# Apply preprocessing to the text column\n",
        "df['Sentence'] = df['Sentence'].apply(preprocess_text)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZm5LWPZJU5d"
      },
      "outputs": [],
      "source": [
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['label'] = label_encoder.fit_transform(df['Emotion'])\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6Ke98QaJU39"
      },
      "outputs": [],
      "source": [
        "# Custom Dataset class\n",
        "class KannadaDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.texts = df['Sentence'].values\n",
        "        self.labels = df['label'].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        return text, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLlScp4KJU0d",
        "outputId": "49b29f86-d50f-4396-c738-031af67e95c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/data/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ],
      "source": [
        "# Define hyperparameters\n",
        "VOCAB_SIZE = 20000\n",
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = len(df['label'].unique())\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 10\n",
        "\n",
        "# Tokenization and padding\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KaFgK21JWwf"
      },
      "outputs": [],
      "source": [
        "def yield_tokens(data_iter):\n",
        "    for text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "train_texts = train_df['Sentence'].tolist()\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_texts), specials=[\"<unk>\", \"<pad>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "def text_pipeline(x):\n",
        "    return vocab(tokenizer(x))\n",
        "\n",
        "def collate_batch(batch):\n",
        "    text_list, label_list = [], []\n",
        "    for _text, _label in batch:\n",
        "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "        text_list.append(processed_text)\n",
        "        label_list.append(torch.tensor(_label, dtype=torch.int64))\n",
        "    text_list = pad_sequence(text_list, batch_first=True, padding_value=vocab[\"<pad>\"])\n",
        "    return text_list, torch.tensor(label_list, dtype=torch.int64)\n",
        "\n",
        "train_dataset = KannadaDataset(train_df)\n",
        "val_dataset = KannadaDataset(val_df)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73n9YPhdJWtC"
      },
      "outputs": [],
      "source": [
        "# Define the LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text)\n",
        "        lstm_out, _ = self.lstm(embedded)\n",
        "        hidden = lstm_out[:, -1, :]\n",
        "        output = self.fc(hidden)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5aoFPJPJWqd",
        "outputId": "1a92f168-b564-4898-d49b-0cb8a0eaf0d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (embedding): Embedding(20000, 128)\n",
              "  (lstm): LSTM(128, 128, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize the model, loss function, and optimizer\n",
        "model = LSTMModel(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBq1T3l3J8HC",
        "outputId": "a6964e60-dee3-4a8d-b191-838ef53852f4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Training loss: 1.8297066601839933\n",
            "Validation loss: 1.5977769759764153, Validation accuracy: 0.29309035687167806\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Training loss: 1.3788450685414402\n",
            "Validation loss: 1.1620666140533356, Validation accuracy: 0.5603644646924829\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Training loss: 0.8820079630071467\n",
            "Validation loss: 1.0040655969137169, Validation accuracy: 0.6416097190584662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Training loss: 0.5478330430207831\n",
            "Validation loss: 1.0189934678106423, Validation accuracy: 0.6492027334851936\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Training loss: 0.3177739474470868\n",
            "Validation loss: 1.1395107633378132, Validation accuracy: 0.6484434320425209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Training loss: 0.16929214933153355\n",
            "Validation loss: 1.2932757392346141, Validation accuracy: 0.6279422930903569\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Training loss: 0.08913660313736535\n",
            "Validation loss: 1.5917679730309062, Validation accuracy: 0.6400911161731208\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Training loss: 0.05092725032679454\n",
            "Validation loss: 1.6357535798865628, Validation accuracy: 0.6438876233864844\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Training loss: 0.028253485100118048\n",
            "Validation loss: 1.7859411097793694, Validation accuracy: 0.6522399392558846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Training loss: 0.022569836874026805\n",
            "Validation loss: 1.5939096406281712, Validation accuracy: 0.6651480637813212\n"
          ]
        }
      ],
      "source": [
        "def train_model(model, train_dataloader, val_dataloader, criterion, optimizer, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for text, labels in tqdm(train_dataloader, desc=f'Epoch {epoch+1}/{epochs}', leave=False):\n",
        "            text, labels = text.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(text)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        print(f'Epoch {epoch+1}, Training loss: {avg_train_loss}')\n",
        "\n",
        "        model.eval()\n",
        "        eval_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for text, labels in val_dataloader:\n",
        "                text, labels = text.to(device), labels.to(device)\n",
        "                outputs = model(text)\n",
        "                loss = criterion(outputs, labels)\n",
        "                eval_loss += loss.item()\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "                correct += (preds == labels).sum().item()\n",
        "\n",
        "        avg_val_loss = eval_loss / len(val_dataloader)\n",
        "        val_accuracy = correct / len(val_dataloader.dataset)\n",
        "        print(f'Validation loss: {avg_val_loss}, Validation accuracy: {val_accuracy}')\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_dataloader, val_dataloader, criterion, optimizer, epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tq-8OFzmKFsH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBHUooCLKFor"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apDD6eFTKFlx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
